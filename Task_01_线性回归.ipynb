{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归\n",
    "主要内容包括：\n",
    "\n",
    "1. 线性回归的基本要素\n",
    "2. 线性回归模型从零开始的实现\n",
    "3. 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的基本要素\n",
    "\n",
    "### 模型\n",
    "为了简单起见，这里我们假设价格只取决于房屋状况的两个因素，即面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 数据集\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "### 损失函数\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n",
    "$$\n",
    "\n",
    "\n",
    "### 优化函数 - 随机梯度下降\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  \n",
    "学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n",
    "批量大小: $\\mathcal{B}$是小批量计算中的批量大小batch size   \n",
    "\n",
    "总结一下，优化函数的有以下两个步骤：\n",
    "\n",
    "- (i)初始化模型参数，一般来说使用随机初始化；\n",
    "- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矢量计算\n",
    "在模型训练或预测时，我们常常会同时处理多个数据样本并用到矢量计算。在介绍线性回归的矢量计算表达式之前，让我们先考虑对两个向量相加的两种方法。\n",
    "\n",
    "\n",
    "1. 向量相加的一种方法是，将这两个向量按元素逐一做标量加法。\n",
    "2. 向量相加的另一种方法是，将这两个向量直接做矢量加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# init variable a, b as 1000 dimension vector\n",
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# init variable a, b as 1000 dimension vector\n",
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)\n",
    "# define a timer class to record time\n",
    "class Timer(object):\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        # start the timer\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        # stop the timer and record time into a list\n",
    "        self.times.append(time.time() - self.start_time)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        # calculate the average and return\n",
    "        return sum(self.times)/len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        # return the sum of recorded time\n",
    "        return sum(self.times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以来测试了。首先将两个向量使用for循环按元素逐一做标量加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.03315 sec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "c = torch.zeros(n)\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外是使用torch来将两个向量直接做矢量加法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00022 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "'%.5f sec' % timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果很明显,后者比前者运算速度更快。因此，我们应该尽可能采用矢量计算，以提升计算效率。\n",
    "\n",
    "## 线性回归模型从零开始的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "# import packages and modules\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据集\n",
    "使用线性模型来生成数据集，生成一个1000个样本的数据集，下面是用来生成数据的线性关系：\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input feature number \n",
    "num_inputs = 2\n",
    "# set example number\n",
    "num_examples = 1000\n",
    "\n",
    "# set true weight and bias in order to generate corresponded label\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.randn(num_examples, num_inputs, dtype=torch.float32)\n",
    "\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float32)  # 添加噪音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 2]), torch.Size([1000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用图像来展示生成的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 0].numpy(), labels.numpy(), 1);  # 约是 y = 2*x + 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);  # 约是 y = -3.4*x + 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    features: 所有参与训练的特征数据 (训练集) -- 本例中shape为 torch.Size([1000, 2]\n",
    "    labels:   所有训练集的标签 (训练集) ------- 本例中shape为 torch.Size([1000])\n",
    "    \"\"\"\n",
    "    num_examples = len(features)  # 1000\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)  # random read 10 samples\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        # the last time may be not enough for a whole batch\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features.index_select(dim=0, index=j), labels.index_select(dim=0, index=j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=6>\n",
    "tensor.index_select(dim, index) <br>\n",
    "</font>\n",
    "<br>\n",
    "\n",
    "<font color=red>\n",
    "dim：表示从第几维挑选数据，类型为int值；<br>\n",
    "index：表示从第一个参数维度中的哪个位置挑选数据，类型为torch.Tensor类的实例 <br>\n",
    "\n",
    "\n",
    "具体实例如下：\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1040,  0.9092],\n",
       "        [ 0.1228, -0.7522],\n",
       "        [-0.0401, -0.1946],\n",
       "        [-1.6273, -0.2487],\n",
       "        [ 0.1193, -1.2524],\n",
       "        [ 0.8567,  2.4284],\n",
       "        [-1.9976,  0.1058],\n",
       "        [-0.5140,  0.2455],\n",
       "        [-0.9692, -0.6059],\n",
       "        [ 0.1350,  0.3094]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第0维（行）, 下标为[192, 768, 584, 201, 923, 497, 634, 355, 349,  29]的数据\n",
    "features.index_select(0, torch.tensor([192, 768, 584, 201, 923, 497, 634, 355, 349,  29]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第1维（列）, 下标为[0， 1]的数据。由于features只有2列, 所以下面的方式返回所有的数据\n",
    "features.index_select(1, torch.tensor([0, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=6>\n",
    "tensor.index_select(dim, index) -- 再举个栗子🌰<br>\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 9., 10., 11., 12.]]) \n",
      "\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 9., 10., 11., 12.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 示例\n",
    "# torch.linspace()生成等差数列的方法, 这里表示[1,12], 生成12个数据, 再reshape\n",
    "a = torch.linspace(1, 12, steps=12).view(3, 4)\n",
    "print(a)\n",
    "b = torch.index_select(a, 0, torch.tensor([0, 2]))\n",
    "print(b, '\\n')\n",
    "print(a.index_select(0, torch.tensor([0, 2])))\n",
    "c = torch.index_select(a, 1, torch.tensor([1, 3]))\n",
    "print(c)\n",
    "\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**正文继续, 看一下data_iter生成的第一个batch的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7480,  1.0902],\n",
      "        [-1.0193, -0.1061],\n",
      "        [ 0.4595,  0.8409],\n",
      "        [ 0.6601, -0.1413],\n",
      "        [-0.3796,  0.1061],\n",
      "        [ 0.6405,  0.2762],\n",
      "        [ 0.5452,  0.1098],\n",
      "        [ 0.9339, -1.8167],\n",
      "        [ 0.4751,  1.0803],\n",
      "        [-0.9177,  0.4198]]) \n",
      " tensor([ 1.9856,  2.5181,  2.2637,  6.0147,  3.0839,  4.5289,  4.9056, 12.2362,\n",
      "         1.4780,  0.9355])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):  # 这里batch_size 为10\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, 1)), dtype=torch.float32)  # num_inputs = 2\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "# requires_grad=True 即作为参数, 可以通过SGD的方式更新\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0036],\n",
       "        [-0.0067]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w  # 注意：w的初始值是随机初始化的, 通过均值为0, 方差为0.01的正态分布 -- np.random.normal(0, 0.01, size=(num_inputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b  # b随机初始化为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "定义用来训练参数的训练模型：\n",
    "\n",
    "$$\n",
    "\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y): \n",
    "    # print(y_hat.shape, y.shape)\n",
    "    return (y_hat - y.view(y_hat.size())) ** 2 / 2\n",
    "    # return (y_hat - y.view(-1)) ** 2 / 2  # 这个不行\n",
    "    # return (y_hat.view(-1) - y) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "测试 损失函数 -- squared_loss( )\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.tensor(np.random.normal(0, 0.01, size=(2, 3)))\n",
    "bb = torch.tensor(np.random.normal(0, 0.01, size=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]), torch.Size([6]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape, bb.shape, aa.view(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "若采用 (y_hat - y.view(-1)) ** 2 / 2 作为损失函数, 计算是会报错, 因为 aa.shape 为(2, 3), bb.shape为torch.Size([6]), 不能广播\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-261d4de2f0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "(aa - bb.view(-1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "即时能广播, loss的计算方法也会错误\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.tensor(np.random.normal(0, 0.01, size=(3, 1)))\n",
    "bb = torch.tensor(np.random.normal(0, 0.01, size=(3, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 1]), torch.Size([3]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape, bb.shape, aa.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(aa - bb.view(-1)).shape  # 若采用(y_hat - y.view(-1)) ** 2 / 2计算损失, 会发生广播。此方法计算损失是错误的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化函数\n",
    "在这里优化函数使用的是小批量随机梯度下降：\n",
    "\n",
    "$$\n",
    "(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n",
    "$$\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  # 随机梯度下降\n",
    "    for param in params:\n",
    "        # ues .data to operate param without gradient track -- 用.data操作参数没有梯度跟踪\n",
    "        param.data -= lr * param.grad / batch_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "当数据集、模型、损失函数和优化函数定义完了之后就可来准备进行模型的训练了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000053\n",
      "epoch 2, loss 0.000053\n",
      "epoch 3, loss 0.000053\n",
      "epoch 4, loss 0.000053\n",
      "epoch 5, loss 0.000053\n",
      "epoch 6, loss 0.000053\n",
      "epoch 7, loss 0.000053\n",
      "epoch 8, loss 0.000053\n",
      "epoch 9, loss 0.000053\n",
      "epoch 10, loss 0.000053\n"
     ]
    }
   ],
   "source": [
    "# super parameters init -- 超参数初始化\n",
    "lr = 0.03\n",
    "num_epochs = 10\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        # 前向传播\n",
    "        l = loss(net(X, w, b), y).sum()\n",
    "        \n",
    "        # 后向传播\n",
    "        # reset parameter gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  # 反向传播 backward() 属于torch.tensor类的一个方法\n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size) # 参数更新\n",
    "        \n",
    "    train_l = loss(net(features, w, b), labels)  # 测试参数[w, b]的效果。train_l的shape为 torch.Size([1000, 1])\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))  # mean()是求均值, item()是获取tensor的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "torch.mean().item() 返回一个值（非tensor类型, 一般是float）, 适合返回loss，acc-- 栗子🌰, 获取tensor的data值, 也可以直接用tensor.data\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), tensor(3.5000), 3.5, float, tensor(3.5000), torch.Tensor)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "cc.shape, cc.mean(), cc.mean().item(), type(cc.mean().item()), cc.mean().data, type(cc.mean().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method backward in module torch.tensor:\n",
      "\n",
      "backward(gradient=None, retain_graph=None, create_graph=False) method of torch.Tensor instance\n",
      "    Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "    \n",
      "    The graph is differentiated using the chain rule. If the tensor is\n",
      "    non-scalar (i.e. its data has more than one element) and requires\n",
      "    gradient, the function additionally requires specifying ``gradient``.\n",
      "    It should be a tensor of matching type and location, that contains\n",
      "    the gradient of the differentiated function w.r.t. ``self``.\n",
      "    \n",
      "    This function accumulates gradients in the leaves - you might need to\n",
      "    zero them before calling it.\n",
      "    \n",
      "    Arguments:\n",
      "        gradient (Tensor or None): Gradient w.r.t. the\n",
      "            tensor. If it is a tensor, it will be automatically converted\n",
      "            to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "            None values can be specified for scalar Tensors or ones that\n",
      "            don't require grad. If a None value would be acceptable then\n",
      "            this argument is optional.\n",
      "        retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "            the grads will be freed. Note that in nearly all cases setting\n",
      "            this option to True is not needed and often can be worked around\n",
      "            in a much more efficient way. Defaults to the value of\n",
      "            ``create_graph``.\n",
      "        create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "            be constructed, allowing to compute higher order derivative\n",
      "            products. Defaults to ``False``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(l.backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0000],\n",
       "         [-3.3992]], requires_grad=True),\n",
       " [2, -3.4],\n",
       " tensor([4.2005], requires_grad=True),\n",
       " 4.2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, true_w, b, true_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>\n",
    "view( ) 方法改变tensor.shape，view(-1) 会降维\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) tensor([0, 1, 2])\n",
      "torch.Size([3, 1]) tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "tensor([[0, 1, 2],\n",
      "        [1, 2, 3],\n",
      "        [2, 3, 4]]) \n",
      "\n",
      "tensor([[0, 1, 2]]) torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "y = torch.arange(3).view(3, 1)\n",
    "print(x.shape, x)\n",
    "print(y.shape, y)\n",
    "print(x + y, '\\n')\n",
    "print(x.view(1, 3), x.view(1, 3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = torch.ones([5, 1])\n",
    "aaa, aaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.]]) torch.Size([1, 5]) \n",
      "----\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "bbb = aaa.view(1, 5)  # aaa的shape无变化\n",
    "print(bbb, bbb.shape, '\\n----\\n',aaa, aaa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc = bbb.view(5, 1)\n",
    "ccc, ccc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>\n",
    "view(-1) 会降维\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) torch.Size([5]) \n",
      "----\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "ddd = aaa.view(-1)\n",
    "\n",
    "print(ddd, ddd.shape, '\\n----\\n',aaa, aaa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.]]), torch.Size([1, 5]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eee = ddd.view(1, 5)\n",
    "eee, eee.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型使用pytorch的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据集\n",
    "在这里生成数据集跟从零开始的实现中是完全一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "\n",
    "# put dataset into DataLoader\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,            # torch TensorDataset format\n",
    "    batch_size=batch_size,      # mini batch size\n",
    "    shuffle=True,               # whether shuffle the data or not\n",
    "    num_workers=2,              # read data in multithreading\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>\n",
    "对torch.utils.data.TensorDataset 类实例 dataset 进行探索性分析\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TensorDataset in module torch.utils.data.dataset object:\n",
      "\n",
      "class TensorDataset(Dataset)\n",
      " |  TensorDataset(*tensors)\n",
      " |  \n",
      " |  Dataset wrapping tensors.\n",
      " |  \n",
      " |  Each sample will be retrieved by indexing tensors along the first dimension.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      *tensors (Tensor): tensors that have the same size of the first dimension.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorDataset\n",
      " |      Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |  \n",
      " |  __init__(self, *tensors)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Dataset:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensors': (tensor([[-0.4015, -2.3459],\n",
       "          [-0.3724, -0.8667],\n",
       "          [-0.6618,  0.7923],\n",
       "          ...,\n",
       "          [-0.5584,  1.0489],\n",
       "          [-0.3105, -0.9365],\n",
       "          [-0.6552,  2.3593]]),\n",
       "  tensor([ 1.1363e+01,  6.3945e+00,  1.7718e-01,  4.4055e+00,  5.0280e+00,\n",
       "           5.0803e+00,  5.2668e+00, -2.6063e-01,  7.3557e+00, -2.2097e-01,\n",
       "           2.0717e+00,  5.2229e+00,  1.2473e+01,  4.5903e+00, -3.1391e+00,\n",
       "           2.5942e+00,  1.0380e+01, -5.4329e+00, -1.1571e-01, -9.5286e-02,\n",
       "           6.9603e+00,  7.7534e+00,  7.4195e+00,  2.4173e+00, -7.4459e+00,\n",
       "          -3.0982e+00,  1.0263e+01,  1.3461e+01,  5.3830e+00,  2.2755e+00,\n",
       "           2.5909e+00,  1.5157e+00,  1.1382e+01,  7.8672e+00, -1.6795e+00,\n",
       "          -2.0625e+00,  3.1818e+00,  7.8080e+00,  1.0041e+01,  6.9196e+00,\n",
       "           6.7267e+00,  8.0879e-01,  2.1176e+00,  6.0676e+00,  8.4298e+00,\n",
       "           1.3806e+00, -1.5615e+00,  2.2692e+00, -3.6675e+00,  1.5654e+00,\n",
       "          -7.8160e-01,  1.3022e+00, -1.4316e-01,  7.3889e+00,  8.1788e+00,\n",
       "           1.7290e+00,  5.6744e+00,  1.0313e+01,  1.1898e+01,  8.0439e+00,\n",
       "           1.1339e+01,  8.6930e+00,  4.1847e+00,  2.6624e+00,  6.3240e+00,\n",
       "           1.1929e+00,  1.2412e+01,  7.6858e+00,  3.5685e+00,  3.0453e+00,\n",
       "           6.4576e+00,  7.0172e+00,  4.7778e+00,  5.6470e+00,  2.0117e+00,\n",
       "           5.2929e+00,  2.1915e+00,  4.1524e-01,  3.5483e+00,  1.1828e+01,\n",
       "           1.8614e+00,  1.6589e+00,  6.1324e+00,  6.8376e+00,  8.6684e+00,\n",
       "           7.4004e+00,  1.0646e+01,  7.9680e+00, -2.0616e+00,  4.2399e+00,\n",
       "           5.4038e+00,  8.9313e+00, -3.2992e+00, -9.0535e+00,  4.2322e+00,\n",
       "           2.5924e+00,  3.0253e+00,  4.8017e+00,  1.4550e+00, -8.0045e-02,\n",
       "          -3.7452e+00,  2.2918e+00,  1.8090e+01, -8.5383e-01,  8.0312e+00,\n",
       "           4.0955e-01, -2.8118e+00,  9.5647e+00,  4.0192e+00,  4.8352e+00,\n",
       "           1.1805e+01, -4.5470e-01,  8.0632e+00,  4.4071e-01,  7.7149e+00,\n",
       "           9.9892e+00, -1.3347e+00,  7.6376e+00, -5.7745e+00, -4.0347e+00,\n",
       "           4.0478e+00,  4.7517e+00,  5.3513e+00, -1.5376e+00,  6.4930e+00,\n",
       "           5.9484e+00,  6.0009e+00, -2.4637e+00,  6.4971e+00,  3.0255e+00,\n",
       "           4.5103e+00,  1.8484e-01,  3.5408e+00, -5.0945e+00,  4.7131e+00,\n",
       "           6.8368e+00,  3.9558e+00, -4.4882e-01, -9.0406e-01, -1.7204e+00,\n",
       "           4.9853e+00,  2.8671e+00, -4.2133e-02,  2.8723e+00, -2.2721e+00,\n",
       "           7.8273e+00,  2.4598e+00,  1.4564e+01,  6.7431e+00,  1.3450e+01,\n",
       "           3.1518e+00,  4.1505e+00,  3.8501e+00,  8.1679e+00,  8.0570e+00,\n",
       "           4.6801e+00, -1.1500e-01,  8.4652e-01,  7.8401e+00,  6.0095e+00,\n",
       "           5.9575e+00,  8.4293e+00, -1.4643e+00,  1.3520e+01,  3.7624e+00,\n",
       "           1.1323e+01,  1.1755e+01,  9.7834e+00,  9.6195e+00,  1.9078e+00,\n",
       "           8.6981e-01,  5.0977e+00,  3.2024e+00,  1.0779e+01,  3.5738e+00,\n",
       "           2.9740e+00,  6.4103e+00,  5.3054e+00,  3.7715e+00,  7.4898e+00,\n",
       "           5.4883e+00,  8.4624e+00,  7.0717e-01,  5.2270e-02,  7.7520e+00,\n",
       "          -1.7930e+00, -2.3376e+00, -8.8938e-01, -2.3925e-01,  4.2109e-01,\n",
       "           3.8375e+00,  3.2398e+00,  5.0499e+00,  1.2940e+00,  6.6956e+00,\n",
       "           3.7655e+00,  4.9014e+00,  4.3773e+00,  2.7932e+00,  1.8351e+00,\n",
       "           6.9670e+00,  2.2185e+00, -3.3660e-01, -3.7107e+00,  4.0952e+00,\n",
       "           1.6142e+00,  5.9614e+00,  3.3882e+00,  5.6142e+00, -1.9552e+00,\n",
       "           2.6308e+00,  1.8611e+00,  3.8667e+00,  2.2435e+00,  3.2271e+00,\n",
       "           5.0804e+00,  3.4823e+00,  1.3972e+00,  9.5077e+00, -3.9394e+00,\n",
       "           3.9761e+00,  3.2301e+00,  3.1286e+00,  2.6280e+00,  7.5739e+00,\n",
       "           8.6417e+00,  2.2794e+00, -2.1482e+00,  6.9872e+00,  8.9224e-01,\n",
       "           6.7198e+00,  5.7608e+00, -2.9834e+00,  1.9468e+00,  8.6283e+00,\n",
       "          -3.8540e-01,  1.2738e+00,  5.7012e+00,  3.0344e+00,  3.3658e+00,\n",
       "           3.3867e+00,  1.2039e+00,  6.2188e+00,  3.0293e+00,  9.8814e+00,\n",
       "           2.2021e+00,  5.7367e+00, -2.3828e-01,  1.6686e+00,  2.8881e-01,\n",
       "          -3.2645e+00,  7.0261e+00, -8.6813e-02,  2.2440e+00,  8.4032e+00,\n",
       "          -1.3134e+00,  3.8827e+00,  7.3374e-01,  4.9639e-01,  5.5678e+00,\n",
       "           3.2360e+00,  4.0782e+00,  4.8291e+00,  1.2530e+00,  6.4655e+00,\n",
       "           7.2906e+00,  6.3698e+00,  5.7282e+00,  6.9000e+00, -1.2228e+00,\n",
       "           4.4075e+00,  7.3597e+00,  5.3915e+00,  1.6618e+00,  7.7392e+00,\n",
       "           1.1398e+00,  9.2289e+00,  5.4918e+00,  8.8312e+00,  3.6426e+00,\n",
       "           5.4211e+00,  4.4960e-01,  2.0548e+00,  3.8624e+00,  4.6157e+00,\n",
       "           1.8072e-03,  4.6929e+00,  1.0815e+01, -5.1633e-01,  9.0515e+00,\n",
       "           4.6490e+00,  3.2127e+00,  1.0544e+01, -8.7287e-01,  2.5397e+00,\n",
       "           1.0361e+01,  1.2103e+01,  9.0863e+00,  4.7162e+00,  5.6213e+00,\n",
       "           1.1452e+01,  1.3504e+00, -1.2070e+00,  5.0947e+00,  1.9365e+00,\n",
       "           6.2336e+00,  4.4663e+00,  7.0704e+00,  6.2593e+00,  6.1419e+00,\n",
       "          -4.6992e-01,  4.7845e+00,  7.5738e+00,  1.1305e+01,  2.4427e+00,\n",
       "           1.9656e+00, -9.4800e-01,  1.5173e+00,  2.2942e+00,  8.3260e-02,\n",
       "           5.0144e+00,  7.5404e-01,  2.7560e+00,  4.7469e+00,  5.2491e+00,\n",
       "           9.4537e+00,  6.7795e+00,  1.6468e+01, -1.9222e+00, -2.0620e+00,\n",
       "           6.3435e+00,  6.3591e+00,  1.1741e+01,  7.0728e-01,  5.5161e+00,\n",
       "           1.3668e-01,  5.3742e+00,  9.3914e+00,  6.7557e+00,  5.0376e+00,\n",
       "           3.2959e+00, -1.2662e+00,  8.1241e+00,  6.1013e+00,  4.4474e+00,\n",
       "           3.0240e+00, -5.5338e+00,  6.7450e+00,  8.9345e+00,  1.0380e+01,\n",
       "           1.2380e+00,  3.9129e+00,  3.5231e+00,  4.6137e+00, -6.4681e-01,\n",
       "           1.2852e+00,  5.5656e+00,  3.2543e+00,  2.1990e+00,  8.8320e+00,\n",
       "           8.1340e+00,  1.4867e+01,  7.6272e+00,  8.1063e+00,  3.3038e+00,\n",
       "           3.0617e+00,  1.0398e+00,  1.0032e+01,  1.9278e+00,  8.6528e+00,\n",
       "          -3.8702e+00,  7.5270e+00,  2.8177e+00,  2.3175e+00, -2.6977e-01,\n",
       "           4.3544e+00, -1.4000e+00,  9.8593e+00, -1.4908e+00,  7.8347e+00,\n",
       "           2.7750e+00,  6.0113e+00,  1.6723e+00,  1.1097e+01,  6.0472e+00,\n",
       "           5.1075e+00,  1.1240e-01,  7.6097e+00,  1.1199e+00,  4.7965e+00,\n",
       "           8.3904e+00,  8.8922e+00,  3.2034e+00,  6.0976e+00,  4.3892e+00,\n",
       "           9.8560e+00,  5.1537e+00,  6.7175e+00,  8.8368e+00,  3.6427e+00,\n",
       "           7.3238e+00,  5.5164e+00,  4.9024e+00,  1.0990e+00,  1.6290e+00,\n",
       "           3.5928e+00,  1.3298e+00,  5.9729e+00,  3.1368e+00, -1.2712e-01,\n",
       "           9.9066e-01,  8.8334e+00,  3.0248e+00,  3.7227e-01, -5.3190e-01,\n",
       "           1.9316e+00,  3.4878e+00,  5.1566e+00, -2.4054e+00,  1.9937e+00,\n",
       "           3.9115e+00,  5.1986e+00, -7.1171e+00,  1.1234e+00,  4.9423e+00,\n",
       "           4.4340e+00,  1.8732e+00,  1.0289e+01,  8.5444e+00,  2.5940e+00,\n",
       "           9.3460e+00,  3.1437e+00,  2.5270e+00,  8.5671e+00,  6.2013e+00,\n",
       "           7.2599e-01,  2.7255e+00,  8.5268e+00,  3.4221e+00,  8.0743e+00,\n",
       "           3.9911e+00, -8.0456e-02,  9.0385e+00,  7.5443e+00,  6.7898e+00,\n",
       "           9.3528e+00,  4.3834e+00,  2.0095e+00,  7.4822e+00,  1.1515e+01,\n",
       "           2.1424e+00, -1.8143e-01,  7.0682e+00,  1.2067e+01,  4.2354e+00,\n",
       "          -5.8318e+00,  3.5999e-01,  8.9309e+00,  3.5293e+00,  8.2698e+00,\n",
       "           6.9821e+00,  3.3085e+00,  4.9510e+00,  2.9868e+00,  7.9401e-01,\n",
       "           5.6536e+00,  1.2041e+00,  7.9109e+00,  6.5646e+00,  6.9915e+00,\n",
       "           3.2193e+00,  3.5394e+00,  2.7214e+00, -2.4848e+00,  8.6661e+00,\n",
       "          -4.0339e+00,  1.4132e+00,  4.0840e+00,  3.8190e+00,  5.5982e+00,\n",
       "           3.3266e+00,  6.3336e+00,  4.8095e+00,  3.7803e+00,  4.7770e+00,\n",
       "           4.4798e+00,  1.6023e+00,  6.3105e+00,  4.2876e+00, -1.6578e+00,\n",
       "           8.0363e+00,  5.2170e-02,  3.5755e+00,  3.9647e-01,  2.3834e+00,\n",
       "          -1.9353e+00,  1.7456e+00,  1.5506e+00,  5.4660e+00,  6.6645e+00,\n",
       "           1.3968e+00, -1.8289e+00, -2.0947e+00,  2.0173e-01,  9.4822e+00,\n",
       "           7.7419e+00, -3.6541e+00,  7.1115e+00, -1.0503e+00, -4.5365e-01,\n",
       "           2.6952e+00,  8.9217e+00,  2.1024e+00,  1.3411e+00, -1.3979e+00,\n",
       "           6.1869e+00, -2.7002e+00, -1.2005e+00,  1.5068e+00,  1.3360e+00,\n",
       "          -5.3021e-02,  4.1881e+00,  3.1634e+00,  1.0032e+01,  1.3464e+01,\n",
       "           5.6466e+00, -2.4832e+00,  2.7555e+00,  3.7317e+00,  2.8981e+00,\n",
       "           7.1659e+00,  2.2705e+00, -3.0732e+00, -2.7581e+00,  9.3545e+00,\n",
       "           2.4350e+00,  5.5992e+00,  8.9735e+00,  5.3202e+00, -1.0072e+00,\n",
       "           1.3284e+01,  7.4546e+00,  1.1870e+00,  7.5653e+00,  1.5059e+00,\n",
       "          -7.3558e-01, -1.1875e+00, -3.4099e-01,  2.4607e+00,  4.8643e+00,\n",
       "          -6.4222e+00,  3.6325e+00,  2.2967e+00,  5.8420e+00,  6.8544e+00,\n",
       "          -5.2377e-01,  2.7433e+00,  7.8865e+00,  6.8673e+00,  5.4897e+00,\n",
       "           7.4199e+00,  8.2869e+00, -2.1269e+00,  5.1027e+00,  3.0724e-01,\n",
       "          -1.4151e+00,  3.4698e+00,  3.0062e+00,  6.0386e-01, -3.5503e+00,\n",
       "           5.5732e+00,  3.8159e+00,  2.0401e+00,  4.1207e+00,  4.7276e+00,\n",
       "          -1.2071e+00,  3.5337e+00,  4.1216e+00, -6.3349e-01, -2.2214e-01,\n",
       "           4.8728e+00,  1.0503e+01,  6.7277e+00, -2.2506e-01,  5.1607e+00,\n",
       "           3.5051e+00,  5.3378e+00,  2.5958e+00,  6.7967e+00,  2.0894e+00,\n",
       "           6.5358e+00, -1.7748e+00,  9.2608e+00,  1.1926e+00,  4.6440e+00,\n",
       "           6.2740e+00,  7.2150e+00,  1.9431e+00,  2.4178e+00,  7.3018e+00,\n",
       "           3.2786e+00,  6.9070e+00,  6.5111e+00,  3.2914e+00,  9.1264e+00,\n",
       "          -2.5410e+00, -5.3415e+00,  8.2395e+00,  4.0489e+00,  6.8824e+00,\n",
       "           6.1566e+00, -4.0804e+00,  4.8936e+00,  2.9030e+00,  9.4837e+00,\n",
       "           5.1871e+00,  5.0898e+00, -1.9955e+00,  8.9232e+00,  3.6752e+00,\n",
       "           3.8360e+00,  9.7654e+00,  7.8828e+00,  3.6180e+00,  3.2209e+00,\n",
       "          -1.8487e+00,  3.9860e+00, -5.3738e-02,  1.6978e+00,  5.5628e+00,\n",
       "           4.5581e+00,  8.2489e+00,  2.1607e+00,  3.1934e+00,  5.5049e+00,\n",
       "           6.1974e+00,  3.3024e+00,  6.8706e+00,  5.1499e+00,  6.1696e+00,\n",
       "           1.5335e+00,  5.2193e+00,  6.4280e+00,  5.9166e-01,  4.7355e+00,\n",
       "           1.7754e+00,  1.0430e+01,  1.9859e+00,  2.5670e+00,  9.6900e+00,\n",
       "           1.4141e-01,  8.1683e+00,  1.2043e+00,  8.3930e-01,  1.5342e+00,\n",
       "           1.0932e+00,  2.4570e+00,  7.9271e+00,  9.0757e+00, -2.3754e-01,\n",
       "           7.9829e+00, -3.5606e+00,  3.4420e+00, -1.0340e+00,  6.4233e+00,\n",
       "          -2.4290e+00, -3.7813e-01, -5.4632e-01, -5.0726e+00,  1.3307e-01,\n",
       "           4.8902e+00,  7.2482e+00,  4.7873e+00,  8.4599e+00,  6.5633e+00,\n",
       "           4.1117e+00,  4.7059e+00,  3.4957e+00, -2.5646e+00,  5.9775e+00,\n",
       "           5.6710e+00,  2.9680e-01,  6.8787e+00,  5.5659e-01,  3.2937e+00,\n",
       "          -2.4274e+00,  5.6977e+00,  5.6483e-01,  3.6372e+00,  1.2936e+01,\n",
       "           6.7815e+00,  6.5077e+00,  1.5611e+00,  6.6942e-01,  1.6603e+00,\n",
       "           2.7137e+00,  1.0419e+00,  2.5176e+00,  1.6900e+00,  2.9868e+00,\n",
       "           1.4731e+00,  3.9516e+00,  5.1998e-02, -1.1662e+00,  3.0950e+00,\n",
       "           6.7773e+00,  6.1713e+00,  3.8375e+00,  4.6113e+00, -1.5951e+00,\n",
       "           4.4604e+00,  3.3875e+00,  6.9355e+00,  6.7185e+00,  3.1241e+00,\n",
       "           3.8297e+00,  9.7835e+00,  6.3637e+00,  4.8508e+00,  7.6835e+00,\n",
       "           7.0800e+00, -2.5643e-01,  2.3521e-01, -5.5042e-01,  4.1913e+00,\n",
       "           2.6479e+00,  5.8383e+00,  4.0643e+00,  1.4837e+00,  7.8123e-01,\n",
       "           3.1909e+00,  1.2246e+01,  1.4887e+00,  3.9518e+00,  5.0296e+00,\n",
       "           1.8075e+00,  3.0680e+00,  1.1715e+01,  7.0339e+00,  1.1706e+00,\n",
       "          -3.5137e-01,  7.1196e+00,  2.7063e+00,  2.7634e+00,  1.8531e+00,\n",
       "           9.5060e+00,  8.6799e+00,  4.7494e+00,  5.9919e+00,  1.1172e+01,\n",
       "           4.0052e+00,  6.2274e+00,  8.3962e+00,  1.3251e+01,  6.2250e+00,\n",
       "           5.1542e+00,  3.1382e+00,  5.7491e+00,  2.2328e+00,  4.3525e+00,\n",
       "           2.3723e+00,  6.7603e+00, -3.8691e-01,  8.0308e-01,  4.9071e+00,\n",
       "           4.8755e+00,  8.9240e+00,  3.6124e-01,  6.7787e+00,  5.1634e+00,\n",
       "           1.1398e+01,  5.5093e+00,  2.1016e+00,  5.7286e-01,  6.7949e+00,\n",
       "          -4.9727e+00,  5.3199e+00,  6.8225e+00,  5.3087e+00,  5.8824e+00,\n",
       "           4.2501e+00,  3.8982e+00,  2.0662e+00,  1.0408e+01,  2.7590e+00,\n",
       "           4.6514e+00,  1.0172e+01,  4.3760e+00,  3.9572e+00,  4.3032e-01,\n",
       "          -6.6851e+00,  7.0802e+00,  7.5064e+00,  4.6667e+00,  5.1897e+00,\n",
       "           6.9065e+00,  1.1037e+01, -2.1087e+00, -6.6980e-01,  2.2547e+00,\n",
       "           6.7419e+00,  5.3162e+00,  3.4422e+00, -6.9394e-01,  1.8143e-01,\n",
       "           3.2315e+00,  9.7539e+00,  7.0304e+00,  4.4141e+00,  9.2375e+00,\n",
       "           4.5178e+00,  3.7908e+00,  6.0682e+00,  9.3850e+00,  5.8256e+00,\n",
       "           1.1385e+01,  3.7598e+00,  3.8092e+00,  8.9971e+00,  3.3885e+00,\n",
       "          -8.7595e-01,  8.4231e+00,  2.2285e+00,  2.6004e+00,  3.9920e+00,\n",
       "           8.4676e+00,  5.4900e+00,  8.2794e+00,  2.9041e+00,  2.7333e+00,\n",
       "           5.3395e+00,  1.9548e+00,  3.5666e+00, -1.1376e+00,  8.0074e+00,\n",
       "           1.8535e+00, -5.9044e-01, -2.2192e+00,  4.6788e+00,  3.4805e+00,\n",
       "           5.7793e+00,  5.6967e+00,  5.0854e+00,  7.4305e+00,  7.4447e+00,\n",
       "           4.8415e+00,  6.0206e+00,  1.0845e+01, -2.9411e+00, -6.3152e-01,\n",
       "           1.0830e+01,  7.6309e+00,  4.9371e+00,  3.7404e+00,  4.6337e+00,\n",
       "           1.3913e+00,  4.1978e+00,  4.5635e+00, -1.3308e+00,  1.4066e+00,\n",
       "           3.4678e+00,  5.3480e+00, -2.3542e+00,  3.4155e+00,  4.8257e+00,\n",
       "           1.0833e+01,  5.8016e+00,  2.2178e+00,  3.7439e+00, -1.6506e+00,\n",
       "           5.6064e+00, -2.6756e-01,  6.6962e+00,  5.2400e+00, -1.2229e+00,\n",
       "           6.6810e+00,  2.2051e+00,  2.1244e+00,  1.9839e-01,  3.7170e+00,\n",
       "          -3.9110e+00,  5.0452e+00,  7.3843e+00,  1.0169e+01,  2.0251e+00,\n",
       "           1.3139e+01,  6.2907e+00,  3.7513e+00,  1.0709e+01,  1.1058e+00,\n",
       "          -1.0728e+00,  3.6620e+00,  1.8041e+00,  9.2495e+00,  5.1624e+00,\n",
       "           9.5169e+00,  5.9359e-01,  1.7252e+00, -4.4016e+00,  3.5462e+00,\n",
       "          -4.3922e+00,  1.1904e+01,  3.1791e+00,  5.3038e+00,  2.5503e-01,\n",
       "          -9.2482e-01,  5.2461e+00,  2.7935e+00,  6.2313e-01,  2.1409e+00,\n",
       "          -1.2311e+00,  7.1389e+00, -8.1450e-02,  7.1640e+00,  4.8061e+00,\n",
       "           8.9484e+00,  1.4564e+00,  1.2212e+00,  7.4528e+00,  5.7336e+00,\n",
       "           6.6409e+00,  4.2933e+00,  5.2088e+00,  6.1117e+00,  4.8222e+00,\n",
       "           4.4093e+00,  2.2535e+00,  7.8257e+00,  1.5356e+00,  4.1069e+00,\n",
       "           2.5910e+00,  6.8764e+00,  5.7114e+00,  7.0985e+00,  3.9785e+00,\n",
       "           1.1276e+01,  3.8522e+00, -1.5956e+00, -1.3395e+00,  4.6916e+00,\n",
       "           6.3975e+00,  4.0147e+00,  8.1370e+00,  2.0185e+00,  2.1309e+00,\n",
       "           8.0761e+00, -1.7213e+00, -1.8499e-01,  1.1113e+00,  2.9800e+00,\n",
       "           5.0031e+00,  4.8364e+00,  9.0749e+00, -1.6716e+00,  9.8314e-01,\n",
       "           4.4121e+00,  2.7976e+00, -2.9400e+00,  7.1174e+00,  8.7164e+00,\n",
       "           8.9768e+00,  4.0921e+00,  9.3931e-01,  4.0629e+00,  3.3444e+00,\n",
       "           5.9598e+00,  8.6226e+00,  5.3550e+00,  2.4128e+00,  7.1576e+00,\n",
       "           6.0970e+00,  4.7633e+00,  1.7918e+01,  4.7524e+00, -1.3690e+00,\n",
       "           9.3844e+00, -6.7054e-01,  9.1068e+00,  1.7210e+00,  3.2059e+00,\n",
       "           9.0525e+00,  2.1529e+00,  3.3164e+00,  1.6409e+01,  4.7839e+00,\n",
       "           5.7189e+00,  3.5459e+00,  5.3858e+00,  2.3558e+00,  9.7482e+00,\n",
       "           5.2347e+00,  3.5985e+00,  1.5800e+00, -1.2818e+00,  7.0847e+00,\n",
       "           1.7690e+00,  4.1874e+00, -4.7609e-01,  6.7598e+00, -5.1245e+00]))}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.__dict__['tensors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 2]), torch.Size([1000]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__dict__['tensors'][0].shape, dataset.__dict__['tensors'][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>\n",
    "torch.utils.data.DataLoader 类返回迭代的对象\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0634, -0.6284],\n",
      "        [ 0.1999,  0.8480],\n",
      "        [ 0.0919, -0.6136],\n",
      "        [-0.1637,  1.5069],\n",
      "        [ 1.2875,  0.3135],\n",
      "        [ 0.4894, -0.8674],\n",
      "        [ 0.0925,  1.8961],\n",
      "        [ 0.6083, -0.7120],\n",
      "        [ 0.0513, -0.2475],\n",
      "        [-0.0852,  2.9050]]) \n",
      " tensor([ 8.4599,  1.7252,  6.4655, -1.2662,  5.7189,  8.1340, -2.0616,  7.8401,\n",
      "         5.1499, -5.8318])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:  # batch_size 为 10\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "\n",
    "由于 线性回归 可以看作是单层的网络模型, 可以直接定义。\n",
    "\n",
    "**但对于多层的网络, 一般会用nn.Sequential() 整合到一起。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):  # n_feature为训练集特征数量\n",
    "        super(LinearNet, self).__init__()      # call father function to init \n",
    "        # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)`\n",
    "        self.linear = nn.Linear(n_feature, 1)  \n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "mid_net = LinearNet(num_inputs)\n",
    "print(mid_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>\n",
    "查看模型（一般命名为net、model）参数\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.weight : torch.Size([1, 2]) \n",
      " Parameter containing:\n",
      "tensor([[0.0874, 0.0100]], requires_grad=True) \n",
      "\n",
      "linear.bias : torch.Size([1]) \n",
      " Parameter containing:\n",
      "tensor([0.6165], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, para in mid_net.named_parameters():\n",
    "    print(name, ':', para.shape, '\\n', para, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三种方法初始化模型 - net\n",
    "\n",
    "**一般第一种方法最常用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# ways to init a multilayer network\n",
    "# method one\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(num_inputs, 1)\n",
    "    # other layers can be added here\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "# method two\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(num_inputs, 1))\n",
    "# net.add_module ......\n",
    "\n",
    "# method three\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(num_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "\"\"\"\n",
    "\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight : torch.Size([1, 2]) \n",
      " Parameter containing:\n",
      "tensor([[ 0.0206, -0.3772]], requires_grad=True) \n",
      "\n",
      "0.bias : torch.Size([1]) \n",
      " Parameter containing:\n",
      "tensor([0.6080], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, para in net.named_parameters():\n",
    "    print(name, ':', para.shape, '\\n', para, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>\n",
    "定义模型的时候，会初始化一遍参数。这里又初始化了一次\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0181, 0.0007]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight : torch.Size([1, 2]) \n",
      " Parameter containing:\n",
      "tensor([[0.0181, 0.0007]], requires_grad=True) \n",
      "\n",
      "0.bias : torch.Size([1]) \n",
      " Parameter containing:\n",
      "tensor([0.], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, para in net.named_parameters():\n",
    "    print(name, ':', para.shape, '\\n', para, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()    # nn built-in squared loss function\n",
    "                       # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "\n",
    "print(optimizer)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, Train Loss: 0.000094\n",
      "epoch: 2, Train Loss: 0.000095\n",
      "epoch: 3, Train Loss: 0.000095\n",
      "epoch: 4, Train Loss: 0.000094\n",
      "epoch: 5, Train Loss: 0.000095\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = 0\n",
    "    for X, y in data_iter:\n",
    "        # 前向传播\n",
    "        output = net(X)\n",
    "        loss = criterion(output, y.view(-1, 1))\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # 计算每个epoch 的平均loss\n",
    "    print('epoch: {}, Train Loss: {:.6f}'.format(epoch, train_loss / len(data_iter))) \n",
    "    # print('epoch %d, loss: %f' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] tensor([[ 2.0001, -3.4001]])\n",
      "4.2 tensor([4.1995])\n"
     ]
    }
   ],
   "source": [
    "# result comparision\n",
    "dense = net[0]\n",
    "print(true_w, dense.weight.data)\n",
    "print(true_b, dense.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
