{"cells":[{"attachments":{"%E5%9B%BE%E7%89%87.png":{"image/png":"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"}},"cell_type":"markdown","metadata":{"graffitiCellId":"id_m8ksq1l","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"ECBDC362D7D147C888F06244BC276561","mdEditEnable":false},"source":"# 循环神经网络\n本节介绍循环神经网络，下图展示了如何基于循环神经网络实现语言模型。我们的目的是基于当前的输入与过去的输入序列，预测序列的下一个字符。循环神经网络引入一个隐藏变量$H$，用$H_{t}$表示$H$在时间步$t$的值。$H_{t}$的计算基于$X_{t}$和$H_{t-1}$，可以认为$H_{t}$记录了到当前字符为止的序列信息，利用$H_{t}$对序列的下一个字符进行预测。\n![Image Name](https://cdn.kesci.com/upload/image/q5jkm0v44i.png?imageView2/0/w/640/h/640)"},{"metadata":{"id":"1501E9868E46429286E75AC573A894DD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 循环神经网络的构造\n\n我们先看循环神经网络的具体构造。假设$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$是时间步$t$的小批量输入，$\\boldsymbol{H}_t  \\in \\mathbb{R}^{n \\times h}$是该时间步的隐藏变量，则：\n\n\n$$\n\\boldsymbol{H}_t = \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hh}  + \\boldsymbol{b}_h).\n$$\n\n\n其中，$\\boldsymbol{W}_{xh} \\in \\mathbb{R}^{d \\times h}$，$\\boldsymbol{W}_{hh} \\in \\mathbb{R}^{h \\times h}$，$\\boldsymbol{b}_{h} \\in \\mathbb{R}^{1 \\times h}$，$\\phi$函数是非线性激活函数。由于引入了$\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hh}$，$H_{t}$能够捕捉截至当前时间步的序列的历史信息，就像是神经网络当前时间步的状态或记忆一样。由于$H_{t}$的计算基于$H_{t-1}$，上式的计算是循环的，使用循环计算的网络即循环神经网络（recurrent neural network）。\n\n在时间步$t$，输出层的输出为：\n\n\n$$\n\\boldsymbol{O}_t = \\boldsymbol{H}_t \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q.\n$$\n\n\n其中$\\boldsymbol{W}_{hq} \\in \\mathbb{R}^{h \\times q}$，$\\boldsymbol{b}_q \\in \\mathbb{R}^{1 \\times q}$。\n\n\n## 从零开始实现循环神经网络\n\n我们先尝试从零开始实现一个基于字符级循环神经网络的语言模型，这里我们使用周杰伦的歌词作为语料，首先我们读入数据："},{"cell_type":"code","execution_count":1,"metadata":{"graffitiCellId":"id_uso50ly","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"20171E08BC064A1DA6315C234E0EDF33","collapsed":false,"scrolled":false},"outputs":[],"source":"import torch\nimport torch.nn as nn\nimport time\nimport math\nimport sys\nimport random\nsys.path.append(\"/home/kesci/input\")\n# import d2l_jay9460 as d2l"},{"metadata":{"id":"8B62219DBF9149EFAD67E72BCB53554B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def load_data_jay_lyrics():\n    with open('/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt') as f:\n        corpus_chars = f.read()\n    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n    print(type(corpus_chars))  # str 类型\n    corpus_chars = corpus_chars[0:10000]  # 只取前10000个字(符)做为训练语料\n    idx_to_char = list(set(corpus_chars))\n    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n    vocab_size = len(char_to_idx)\n    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n    return corpus_indices, char_to_idx, idx_to_char, vocab_size","execution_count":2},{"metadata":{"id":"91E5E8A65877499483BAD0F2332437A0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"<class 'str'>\n","name":"stdout"}],"source":"(corpus_indices, char_to_idx, idx_to_char, vocab_size) = load_data_jay_lyrics()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":3},{"metadata":{"id":"7F940CDD005D408A80847F4703FAFC30","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"device(type='cpu')"},"transient":{},"execution_count":4}],"source":"device","execution_count":4},{"metadata":{"id":"CAE5E3123A04465CB8F8B7B6DB0D4DA8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"1027\n","name":"stdout"}],"source":"print(vocab_size)","execution_count":5},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_kryzk9x","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"797F389C048341748C8B9D95206722C6","mdEditEnable":false},"source":"### one-hot向量\n\n我们需要将字符表示成向量，这里采用one-hot向量。假设词典大小是$N$，每次字符对应一个从$0$到$N-1$的唯一的索引，则该字符的向量是一个长度为$N$的向量，若字符的索引是$i$，则该向量的第$i$个位置为$1$，其他位置为$0$。下面分别展示了索引为0和2的one-hot向量，向量长度等于词典大小。"},{"cell_type":"code","execution_count":6,"metadata":{"graffitiCellId":"id_vljucfa","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0A8DFF6F37CA40C1B87AAF9D0D361497","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.]])\ntorch.Size([2, 1027])\ntensor([1., 1.])\n","name":"stdout"}],"source":"def one_hot(x, n_class, dtype=torch.float32):\n    result = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)  # shape: (n, n_class)\n    # x.shape为tensor([0, 2])，x.long().view(-1, 1)的shape为torch.Size([2, 1])\n    # 即 tensor([[one],\n    #            [two]])\n    result.scatter_(dim=1, index=x.long().view(-1, 1), src=torch.tensor(1))  # result[i, x[i, 0]] = 1\n    return result\n    \nx = torch.tensor([0, 2])\nx_one_hot = one_hot(x, vocab_size)  # vocab_size = 1027\nprint(x_one_hot)\nprint(x_one_hot.shape)\nprint(x_one_hot.sum(axis=1))"},{"metadata":{"id":"4CC8AA6A6FAA48F7A7F775E837DCCAAD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.6494,  0.6231,  1.2853, -1.8177],\n        [ 1.4094,  0.7331,  1.0617, -0.3743]])\ntensor([[-1.8177,  0.6231,  1.2853,  0.6494,  0.0000],\n        [ 1.0617,  1.4094,  0.7331, -0.3743,  0.0000]])\n","name":"stdout"}],"source":"# tensor.scatter_() 示例\nimport torch\n \ninput = torch.randn(2, 4)\nprint(input)\noutput = torch.zeros(2, 5)\nindex = torch.tensor([[3, 1, 2, 0], [1, 2, 0, 3]])\noutput = output.scatter(dim=1, index=index, src=input)\nprint(output)","execution_count":7},{"metadata":{"id":"300CBA61F0E349108C0C3308434EF176","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"[tensor.scatter_()用法](https://blog.csdn.net/qq_39004117/article/details/95665418)"},{"metadata":{"id":"D00A838ECD714C26BCF04FF485A80E8D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"### 三维\n```\nout[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\nout[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\nout[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n```\n\n### 二维\n```\nout[index[i][j]][j] = src[i][j]  # if dim == 0\nout[i][index[i][j]] = src[i][j]  # if dim == 1\n\n例如：上面的例子，dim = 1 ， a -> b 表示将a的值赋予b，即b = a\ninput[0][0] -> out[0][index[0][0]] -> out[0][3] = -1.1520 即 out[0][3] = input[0][0]\ninput[0][1] -> out[0][index[0][1]] -> out[0][1] =  1.6093 即 out[0][1] = input[0][1]\ninput[0][2] -> out[0][index[0][2]] -> out[0][2] =  1.3236 即 out[0][2] = input[0][2]\ninput[0][3] -> out[0][index[0][3]] -> out[0][0] = -0.8939 即 out[0][0] = input[0][3]\n\n```"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_eaelzjl","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A01C821C29E54ECA95AF07E01A4997D6","mdEditEnable":false},"source":"我们每次采样的小批量的形状是（批量大小, 时间步数）。下面的函数将这样的小批量变换成数个形状为（批量大小, 词典大小）的矩阵，矩阵个数等于时间步数。也就是说，时间步$t$的输入为$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$，其中$n$为批量大小，$d$为词向量大小，即one-hot向量长度（词典大小）。"},{"cell_type":"code","execution_count":8,"metadata":{"graffitiCellId":"id_961roi7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"781B54CB28D741D9B8C2931ABD71F7F7","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"1: torch.Size([2, 5])\n2: 5 torch.Size([2, 1027])\n3: tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])\n4: tensor([1, 6])\n","name":"stdout"}],"source":"def to_onehot(X, n_class):  # n_class 为类别数量，这里指vocab_size的大小\n    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]\n\nX = torch.arange(10).view(2, 5)\nprint('1:', X.shape)\ninputs = to_onehot(X, vocab_size)  # vocab_size = 1027\nprint('2:', len(inputs), inputs[0].shape)  # inputs为list, [tensor2d, rensor2d, ... ]\nprint('3:', inputs[1])\nprint('4:', X[:, 1])"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_6nii7n3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"323AB87BB02246F38BD4BB86219530E0","mdEditEnable":false},"source":"### 初始化模型参数\n"},{"cell_type":"code","execution_count":9,"metadata":{"graffitiCellId":"id_4667brq","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"C1F685ED1624479186E895EEECED6499","collapsed":false,"scrolled":false},"outputs":[],"source":"num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size  # vocab_size = 1027\n# num_inputs: d\n# num_hiddens: h, 隐藏单元的个数是超参数\n# num_outputs: q\n\ndef get_params():\n    def _one(shape):\n        param = torch.zeros(shape, device=device, dtype=torch.float32)\n        nn.init.normal_(param, 0, 0.01)\n        # 将这个parameter绑定到这个module里面\n        # (net.parameter()中就有这个绑定的parameter，所以在参数优化的时候可以进行优化的)\n        # 这里的param就变成了模型的一部分\n        # Reference: https://www.jianshu.com/p/d8b77cc02410\n        return torch.nn.Parameter(param)\n\n    # 隐藏层参数\n    W_xh = _one((num_inputs, num_hiddens))\n    W_hh = _one((num_hiddens, num_hiddens))\n    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device))\n    # 输出层参数\n    W_hq = _one((num_hiddens, num_outputs))\n    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device))\n    return (W_xh, W_hh, b_h, W_hq, b_q)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_ge2je0t","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"5C9E578391F04E988B0AF4415BB33767","mdEditEnable":false},"source":"### 定义模型\n\n函数`rnn`用循环的方式依次完成循环神经网络每个时间步的计算。\n"},{"cell_type":"code","execution_count":10,"metadata":{"graffitiCellId":"id_ffheq7o","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"E2C02FC273C543DE845D4CFD8F6B99EB","collapsed":false,"scrolled":false},"outputs":[],"source":"def rnn(inputs, state, params):\n    # inputs和outputs皆为num_steps个形状为(batch_size, vocab_size)的矩阵\n    W_xh, W_hh, b_h, W_hq, b_q = params\n    H, = state  # 隐藏变量H初始化为全0\n    outputs = []\n    for X in inputs:\n        # X.shape = (2*1027), W_xh.shape = (num_inputs, num_hiddens) = (1027*256)\n        # H.shape = (2*256)\n        # W_hh.shape = (num_hiddens, num_hiddens) = (256*256)\n        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n        # H.shape = (2*256)\n        # W_hq = (num_hiddens, num_outputs) = (256*1027)\n        Y = torch.matmul(H, W_hq) + b_q  # Y.shape = X.shape = (2*1027)\n        outputs.append(Y)\n    return outputs, (H,)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_ap3wbu6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"6C4A4D9C506C4FD6953F9E0770A1D35A","mdEditEnable":false},"source":"**函数init_rnn_state初始化隐藏变量，这里的返回值是一个元组。：\n**"},{"cell_type":"code","execution_count":11,"metadata":{"graffitiCellId":"id_ogd1cln","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"79F6F77218D44C20A99A85D8CBD26DD3","collapsed":false,"scrolled":false},"outputs":[],"source":"# 隐藏变量初始化为全0\ndef init_rnn_state(batch_size, num_hiddens, device):\n    return (torch.zeros((batch_size, num_hiddens), device=device), )"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_cnjj602","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"006CB36276C74F5DBE8D4988915F99CB","mdEditEnable":false},"source":"做个简单的测试来观察输出结果的个数（时间步数），以及第一个时间步的输出层输出的形状和隐藏状态的形状。"},{"metadata":{"id":"DB217683D5754CFEB959436D912051A7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"1"},"transient":{},"execution_count":12}],"source":"len(init_rnn_state(X.shape[0], num_hiddens, device))","execution_count":12},{"metadata":{"id":"4B6A77DDA3C448EA808538D416CFF0BB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tuple"},"transient":{},"execution_count":13}],"source":"type(init_rnn_state(X.shape[0], num_hiddens, device))  # 返回的是(tensor, )的形式","execution_count":13},{"metadata":{"id":"20F2E313DE044BA28147F9CE8645C4B4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"torch.Size([2, 256])"},"transient":{},"execution_count":14}],"source":"mid, = init_rnn_state(X.shape[0], num_hiddens, device)\nmid.shape","execution_count":14},{"cell_type":"code","execution_count":15,"metadata":{"graffitiCellId":"id_5rof9df","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"DFFE1C2E29C9414A86EAB4D70A62A911","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"torch.Size([2, 5])\n256\n1027\n5 torch.Size([2, 1027])\n5 torch.Size([2, 1027])\n1 torch.Size([2, 256])\n1 torch.Size([2, 256])\n","name":"stdout"}],"source":"print(X.shape)\nprint(num_hiddens)\nprint(vocab_size)\nstate = init_rnn_state(X.shape[0], num_hiddens, device)  # 隐藏变量H初始化为全0\ninputs = to_onehot(X.to(device), vocab_size)\nparams = get_params()\noutputs, state_new = rnn(inputs, state, params)\nprint(len(inputs), inputs[0].shape)\nprint(len(outputs), outputs[0].shape)\nprint(len(state), state[0].shape)\nprint(len(state_new), state_new[0].shape)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_zrzqvc3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"7C5463AD4B364F0290B4E4A36A712481","mdEditEnable":false},"source":"### 裁剪梯度\n\n循环神经网络中较容易出现梯度衰减或梯度爆炸，这会导致网络几乎无法训练。裁剪梯度（clip gradient）是一种应对梯度爆炸的方法。假设我们把所有模型参数的梯度拼接成一个向量 $\\boldsymbol{g}$，并设裁剪的阈值是$\\theta$。裁剪后的梯度\n\n\n$$\n \\min\\left(\\frac{\\theta}{\\|\\boldsymbol{g}\\|}, 1\\right)\\boldsymbol{g}\n$$\n\n\n的$L_2$范数不超过$\\theta$。\n"},{"cell_type":"code","execution_count":16,"metadata":{"graffitiCellId":"id_ddfzc4y","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"4845C2DF302D45B68317E8C65B9691C0","collapsed":false,"scrolled":false},"outputs":[],"source":"def grad_clipping(params, theta, device):\n    norm = torch.tensor([0.0], device=device)\n    for param in params:\n        norm += (param.grad.data ** 2).sum()  # norm 是一个浮点数\n    norm = norm.sqrt().item()\n    if norm > theta:\n        for param in params:\n            param.grad.data *= (theta / norm)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_qz5cf4d","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8C548F77B1F642E1BE5C4758F2834AF7","mdEditEnable":false},"source":"### 定义预测函数\n\n以下函数基于前缀`prefix`（含有数个字符的字符串）来预测接下来的`num_chars`个字符。这个函数稍显复杂，其中我们将循环神经单元`rnn`设置成了函数参数，这样在后面小节介绍其他循环神经网络时能重复使用这个函数。\n"},{"cell_type":"code","execution_count":17,"metadata":{"graffitiCellId":"id_e4mi857","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"228D7151704A45718C388511E8A0D1A6","collapsed":false,"scrolled":false},"outputs":[],"source":"def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\n    \"\"\"\n    num_chars: 要预测的字符串的长度（不包含前缀长度）\n    \"\"\"\n    state = init_rnn_state(1, num_hiddens, device)\n    output = [char_to_idx[prefix[0]]]   # output记录prefix加上预测的num_chars个字符\n    for t in range(num_chars + len(prefix) - 1):\n        # 将上一时间步的输出作为当前时间步的输入\n        # X 为只含有一个元素的list， [ torch.Size([1, 1027]) ]， Y也是[ torch.Size([1, 1027]) ]\n        X = to_onehot(torch.tensor([[output[-1]]], device=device), vocab_size)  # idx -> one-hot\n        \n        # 计算输出和更新隐藏状态\n        (Y, state) = rnn(X, state, params)\n        \n        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])  # 下一个时间步的输入是 prefix里的字符\n        else:\n            output.append(Y[0].argmax(dim=1).item())   # 下一个时间步的输入是 当前的最佳预测字符\n    return ''.join([idx_to_char[i] for i in output])"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_157mdwx","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"5F877F47755642A299DF44270D5B7C54","mdEditEnable":false},"source":"我们先测试一下`predict_rnn`函数。我们将根据前缀“分开”创作长度为10个字符（不考虑前缀长度）的一段歌词。因为模型参数为随机值，所以预测结果也是随机的。"},{"cell_type":"code","execution_count":18,"metadata":{"graffitiCellId":"id_slr2lmi","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"753869000A07429384C791FD3131BEF8","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'分开征驳怪宇蝪悄拽垂白袋'"},"transient":{},"execution_count":18}],"source":"predict_rnn('分开', 10, rnn, params, init_rnn_state, num_hiddens, vocab_size,\n            device, idx_to_char, char_to_idx)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_kasti5n","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"CECD70B6BFE348AD94C9B45DBEB604AE","mdEditEnable":false},"source":"### 困惑度\n\n我们通常使用困惑度（perplexity）来评价语言模型的好坏。回忆一下[“softmax回归”](../chapter_deep-learning-basics/softmax-regression.ipynb)一节中交叉熵损失函数的定义。困惑度是对交叉熵损失函数做指数运算后得到的值。特别地，\n\n* 最佳情况下，模型总是把标签类别的概率预测为1，此时困惑度为1；\n* 最坏情况下，模型总是把标签类别的概率预测为0，此时困惑度为正无穷；\n* 基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数。\n\n显然，任何一个有效模型的困惑度必须小于类别个数。在本例中，困惑度必须小于词典大小`vocab_size`。\n\n### 定义模型训练函数\n\n跟之前章节的模型训练函数相比，这里的模型训练函数有以下几点不同：\n\n1. 使用困惑度评价模型。\n2. 在迭代模型参数前裁剪梯度。\n3. 对时序数据采用不同采样方法将导致隐藏状态初始化的不同。"},{"metadata":{"id":"6FE2B1C4D9FD4CB2BABD11436B1981BA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 随机采样\ndef data_iter_random(corpus_indices, batch_size, num_steps, device=None):\n    # 减1是因为输出的索引x是相应输入的索引y加1\n    num_examples = (len(corpus_indices) - 1) // num_steps\n    epoch_size = num_examples // batch_size\n    example_indices = list(range(num_examples))\n    random.shuffle(example_indices)\n\n    # 返回从pos开始的长为num_steps的序列\n    def _data(pos):\n        return corpus_indices[pos: pos + num_steps]\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    for i in range(epoch_size):\n        # 每次读取batch_size个随机样本\n        i = i * batch_size\n        batch_indices = example_indices[i: i + batch_size]\n        X = [_data(j * num_steps) for j in batch_indices]\n        Y = [_data(j * num_steps + 1) for j in batch_indices]\n        yield torch.tensor(X, dtype=torch.float32, device=device), torch.tensor(Y, dtype=torch.float32, device=device)\n        \n","execution_count":19},{"metadata":{"id":"16CCBEC286514DB58F2D51E73BF649AC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 相邻采样\ndef data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\n    data_len = len(corpus_indices)\n    batch_len = data_len // batch_size\n    indices = corpus_indices[0: batch_size*batch_len].view(batch_size, batch_len)\n    epoch_size = (batch_len - 1) // num_steps\n    for i in range(epoch_size):\n        i = i * num_steps\n        X = indices[:, i: i + num_steps]\n        Y = indices[:, i + 1: i + num_steps + 1]\n        yield X, Y","execution_count":20},{"metadata":{"id":"25A2B3C9C6E34AB998A757A573C1E3DA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def sgd(params, lr, batch_size):\n    # 为了和原书保持一致，这里除以了batch_size，但是应该是不用除的，因为一般用PyTorch计算loss时就默认已经\n    # 沿batch维求了平均了。\n    for param in params:\n        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data","execution_count":21},{"metadata":{"id":"B5941A9C74D24E3388D44694208C9EE6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"([40, 129, 981, 553, 781, 100, 661, 40, 129, 856], 10000)"},"transient":{},"execution_count":22}],"source":"corpus_indices[:10], len(corpus_indices)","execution_count":22},{"cell_type":"code","execution_count":24,"metadata":{"graffitiCellId":"id_yzrgxwe","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"9FE06ACC79564A21B427C2AB90AC5BAA","collapsed":false,"scrolled":false},"outputs":[],"source":"def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                          vocab_size, device, corpus_indices, idx_to_char,\n                          char_to_idx, is_random_iter, num_epochs, num_steps,\n                          lr, clipping_theta, batch_size, pred_period,\n                          pred_len, prefixes):\n    \"\"\"\n    num_steps: 每次采样的样本长度\n    is_random_iter: bool类型, True表示随机采样，False表示相邻采样\n    pred_period:  每训练多少次 输出一次结果，这里是50\n    pred_len:  给出前缀词prefixes，预测后面的pred_len个词\n    prefixes: 前缀词\n    \"\"\"\n    if is_random_iter:\n        data_iter_fn = data_iter_random\n    else:\n        data_iter_fn = data_iter_consecutive\n    params = get_params()\n    loss = nn.CrossEntropyLoss()\n\n    for epoch in range(num_epochs):\n        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\n            state = init_rnn_state(batch_size, num_hiddens, device)\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device)\n        for X, Y in data_iter:\n            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\n                state = init_rnn_state(batch_size, num_hiddens, device)\n            else:  # 否则需要使用detach函数从计算图分离隐藏状态，这时的隐藏状态只初始为全0，\n                # 每次迭代计算，不参与梯度计算\n                for s in state:\n                    s.detach_()\n            # inputs是num_steps个形状为(batch_size, vocab_size)的矩阵\n            inputs = to_onehot(X, vocab_size)\n            # outputs有num_steps个形状为(batch_size, vocab_size)的矩阵\n            (outputs, state) = rnn(inputs, state, params)\n            # 拼接之后形状为(num_steps * batch_size, vocab_size)\n            outputs = torch.cat(outputs, dim=0)\n            # Y的形状是(batch_size, num_steps)，转置后再变成形状为\n            # (num_steps * batch_size,)的向量，这样跟输出的行一一对应\n            y = torch.flatten(Y.T)\n            # 使用交叉熵损失计算平均分类误差，注意CrossEntropy用法\n            l = loss(outputs, y.long())  # torch.long() 将tensor投射为long类型\n            # print(outputs.shape, y.long().shape)  # torch.Size([1120, 1027]) torch.Size([1120])\n            \n            # 梯度清0\n            if params[0].grad is not None:\n                for param in params:\n                    param.grad.data.zero_()\n            l.backward()\n            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n            sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n            l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n\n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n                    num_hiddens, vocab_size, device, idx_to_char, char_to_idx))"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_abcvmn2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"BC331C0942B549DD9CE8FF1D5FF1AA39","mdEditEnable":false},"source":"### 训练模型并创作歌词\n\n现在我们可以训练模型了。首先，设置模型超参数。我们将根据前缀“分开”和“不分开”分别创作长度为50个字符（不考虑前缀长度）的一段歌词。我们每过50个迭代周期便根据当前训练的模型创作一段歌词。"},{"cell_type":"code","execution_count":25,"metadata":{"graffitiCellId":"id_r49e5nv","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"528CB0DB2860481C8C803D377E5B5C89","collapsed":false,"scrolled":false},"outputs":[],"source":"num_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\npred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_fvpvu53","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"867977FACDBE43528C0E17B7EC702F2C","mdEditEnable":false},"source":"下面采用随机采样训练模型并创作歌词。"},{"metadata":{"id":"15910B29DB974EAA8B6D251651A584F4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"epoch 50, perplexity 67.313510, time 0.87 sec\n - 分开 我想要你想你 我不要你的爱 我不要你的爱 我不要你的爱 我不要你的爱 我不要你的爱 我不要你的爱 \n - 不分开 爱要你的生写 我不要你不 我不要再想你 我不要你的爱我 我想要你不 我不要再想你 我不要你的爱我 \nepoch 100, perplexity 9.733288, time 0.68 sec\n - 分开 一颗用 有不的让我 红的可爱女人 透坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯\n - 不分开堡 我后能 你爱我 我想就这样牵着你的手不放开 爱可不 你给的让我疯红的可爱女人 坏柔的让我疯狂的可\nepoch 150, perplexity 2.764272, time 0.68 sec\n - 分开 爱想是没有 二我温红乡球信命我 在散一 几步时不起球 它说哈兮我妈轻 却我现 你沉已 一壶两 旧沉\n - 不分开期 我后你好 你打我妈 这样 一个意酒 戒指好哭 耍不夜梦 你一定空 你自不通 你不懂 连一句珍重 \nepoch 200, perplexity 1.532843, time 0.67 sec\n - 分开 爱在心 一步两步三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿 看远方的星是否\n - 不分开扫把的胖女巫 用拉丁文念咒语啦啦呜 她养的黑猫笑起来像哭 啦啦啦呜 我妈我将说活你 一壶好酒有再不了\nepoch 250, perplexity 1.281982, time 0.69 sec\n - 分开 爱什么 一步两步三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿 看远方的星如果\n - 不分开期 然后将过去 慢慢温习 让我爱上你 那场悲剧 是你完美演出的一场戏 宁愿心碎哭泣 再狠狠忘记 你爱\n","name":"stdout"}],"source":"train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                      vocab_size, device, corpus_indices, idx_to_char,\n                      char_to_idx, True, num_epochs, num_steps, lr,\n                      clipping_theta, batch_size, pred_period, pred_len,\n                      prefixes)","execution_count":51},{"metadata":{"id":"82ACA69C538644B78BE413B4E13CF3EB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 可以发现 不同的初始化参数，最后输出的结果是类似的"},{"cell_type":"code","execution_count":54,"metadata":{"graffitiCellId":"id_xnnajux","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B020BFA4A5A442D285BB1A7FC65BEA2E","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 50, perplexity 67.800381, time 0.71 sec\n - 分开 我不要再想你的让我 甩的可爱女人 哼知的觉 我已了这 你有我有 你想了这 你有我有 你想了这 你有\n - 不分开 我不要再想 我不要的可爱女人 透坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的\nepoch 100, perplexity 10.171657, time 0.78 sec\n - 分开 一颗两双三棍我单妈 我说的话 你知的让我面红的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的\n - 不分开吗 我不能再想你 不知不觉 你已经离 我给后知 你知的让 我跟定努 恨果的外 你人放空 你一定空 在\nepoch 150, perplexity 2.862187, time 0.79 sec\n - 分开 一直心停子  让悔着对里 一天 这截棍 后词不  一些风霜凉  什悔文对 有故伦头 在一场纵  没\n - 不分开吗 我叫你爸 你知我有 这样的让我面红的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人\nepoch 200, perplexity 1.577382, time 0.77 sec\n - 分开 干愿底不里 谁话都乌难 别里什么奇怪的事都有 包括像猫的狗 印地安老斑鸠 平常话不多 除非是乌鸦抢\n - 不分开扫 我不能爸生  没有你烦我有多难恼多难熬  穿过云层 我试著努力向你奔跑 爱才送到 你却已在节人怀\nepoch 250, perplexity 1.323946, time 0.73 sec\n - 分开 干时的老丽 你的完美主义 太彻底我的泪真幽动 在红再重演经 哼哼哈兮 如果我有轻功 飞檐走壁 为人\n - 不分开简 然后将过去 慢慢温习 让我爱上你 那场悲剧 是你完美演出的一场戏 宁愿心碎哭泣 再狠狠忘记 你爱\n","name":"stdout"}],"source":"train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                      vocab_size, device, corpus_indices, idx_to_char,\n                      char_to_idx, True, num_epochs, num_steps, lr,\n                      clipping_theta, batch_size, pred_period, pred_len,\n                      prefixes)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_t650z1s","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"CC35E4A71367440F8EBB8C8F13F50677","mdEditEnable":false},"source":"接下来采用相邻采样训练模型并创作歌词。"},{"cell_type":"code","execution_count":58,"metadata":{"graffitiCellId":"id_5cubvww","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"60A46F92EC144D4A81FFC0D73850D275","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 50, perplexity 58.474331, time 0.62 sec\n - 分开 我想要你 你你的外 如果用人 泪谁一人 泪谁一人 泪果一人 泪谁一人 泪谁一人 泪果一人 泪谁一人\n - 不分开 我想要你 你你了外 我想一直 泪你一直 如果一人 泪谁一人 泪谁一人 泪果一人 泪谁一人 泪谁一人\nepoch 100, perplexity 7.376631, time 0.64 sec\n - 分开 我说想这生活 我想好好 又我的外婆家 一起看着的牛肉 我说店小二 三两银够不  没有你在我有多 就\n - 不分开柳 你不经离 我想说带 在让己空 我有的梦 我面著带节人 后知后觉 快使了一个棍 哼哼哈兮 快使用双\nepoch 150, perplexity 2.122068, time 0.69 sec\n - 分开 我 想带你骑棒车 我这想你和忧我妈妈 为才你手不会痛吗 不要我这做得想 但那伦我 经来 那壶我的后\n - 不分开觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 又过了一个秋 后知后觉 我该好好生活 我该好好生\nepoch 200, perplexity 1.285781, time 0.63 sec\n - 分开 我叫想这样对 我静带你 回我的外婆家 一起看着日落 一直到我们都睡着 我想就这样牵着你的手不放开 \n - 不分开觉太就多 泪说你 有我眼好看着  别人了其快我 甩散球 快给我 印你说那 说我马直是 我一直 一烧空\nepoch 250, perplexity 1.212777, time 0.68 sec\n - 分开 在候跟 娘属我 印地安的传说 还真是 瞎透了 什么都有 这故之中 都隐作痛 我不懂受我 我不懂很想\n - 不分开觉太经天 不要你多手 让我却依不打 篮后在这里 除非是乌鸦抢了它的窝 它在灌木丛旁邂逅 一只令它心仪\n","name":"stdout"}],"source":"train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                      vocab_size, device, corpus_indices, idx_to_char,\n                      char_to_idx, False, num_epochs, num_steps, lr,\n                      clipping_theta, batch_size, pred_period, pred_len,\n                      prefixes)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_k40p6v8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"868B10D9B4DE4D0B93E79F5746A49D47","mdEditEnable":false},"source":"## 循环神经网络的简介实现\n\n### 定义模型\n\n我们使用Pytorch中的`nn.RNN`来构造循环神经网络。在本节中，我们主要关注`nn.RNN`的以下几个构造函数参数：\n\n* `input_size` - The number of expected features in the input x\n* `hidden_size` – The number of features in the hidden state h\n* `nonlinearity` – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'\n* `batch_first` – If True, then the input and output tensors are provided as (batch_size, num_steps, input_size). Default: False\n\n这里的`batch_first`决定了输入的形状，我们使用默认的参数`False`，对应的输入形状是 (num_steps, batch_size, input_size)。\n\n`forward`函数的参数为：\n\n* `input` of shape (num_steps, batch_size, input_size): tensor containing the features of the input sequence. \n* `h_0` of shape (num_layers * num_directions, batch_size, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n\n`forward`函数的返回值是：\n\n* `output` of shape (num_steps, batch_size, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the RNN, for each t.\n* `h_n` of shape (num_layers * num_directions, batch_size, hidden_size): tensor containing the hidden state for t = num_steps.\n\n现在我们构造一个`nn.RNN`实例，并用一个简单的例子来看一下输出的形状。"},{"cell_type":"code","execution_count":71,"metadata":{"graffitiCellId":"id_j3cpkcl","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0299EF9E9126417B80153A137538E01E","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"torch.Size([35, 2, 1027]) torch.Size([35, 2, 256]) torch.Size([1, 2, 256])\n","name":"stdout"}],"source":"rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)\nnum_steps, batch_size = 35, 2\nX = torch.rand(num_steps, batch_size, vocab_size)\nstate = None\nY, state_new = rnn_layer(X, state)\nprint(X.shape, Y.shape, state_new.shape)\n# 这里Y.shape的最后一个维度为num_hiddens"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_m47aq8s","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"069F7F5EE53E47FA9E67B386F372D166","mdEditEnable":false},"source":"我们定义一个完整的基于循环神经网络的语言模型。"},{"cell_type":"code","execution_count":72,"metadata":{"graffitiCellId":"id_syy2qdo","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"9B2540FE03B44485818E407213E44E82","collapsed":false,"scrolled":false},"outputs":[],"source":"class RNNModel(nn.Module):\n    def __init__(self, rnn_layer, vocab_size):\n        super(RNNModel, self).__init__()\n        self.rnn = rnn_layer\n        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \n        self.vocab_size = vocab_size\n        self.dense = nn.Linear(self.hidden_size, vocab_size)  # 这里的vocab_size=1027为output.shape的最后一维\n\n    def forward(self, inputs, state):\n        # inputs.shape: (batch_size, num_steps)\n        X = to_onehot(inputs, vocab_size)\n        X = torch.stack(X)  # X.shape: (num_steps, batch_size, vocab_size)\n        hiddens, state = self.rnn(X, state)\n        hiddens = hiddens.view(-1, hiddens.shape[-1])  # hiddens.shape: (num_steps * batch_size, hidden_size)\n        output = self.dense(hiddens)\n        return output, state"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_soot8nz","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"288D99C0B51F45659BB0F39C2B5AAD9B","mdEditEnable":false},"source":"类似的，我们需要实现一个预测函数，与前面的区别在于前向计算和初始化隐藏状态。"},{"cell_type":"code","execution_count":73,"metadata":{"graffitiCellId":"id_dkebt7t","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"470CA7EEF6C2443980C3D327EB4BAD73","collapsed":false,"scrolled":false},"outputs":[],"source":"def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n                      char_to_idx):\n    state = None\n    output = [char_to_idx[prefix[0]]]  # output记录prefix加上预测的num_chars个字符\n    for t in range(num_chars + len(prefix) - 1):\n        X = torch.tensor([output[-1]], device=device).view(1, 1)\n        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])\n        else:\n            output.append(Y.argmax(dim=1).item())\n    return ''.join([idx_to_char[i] for i in output])"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_6dx4k76","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A1009A6DA48749D883D7DEE75F8B55EF","mdEditEnable":false},"source":"使用权重为随机值的模型来预测一次。"},{"cell_type":"code","execution_count":74,"metadata":{"graffitiCellId":"id_dovnvrc","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"7000F425557A4047A9D7B0BD446C4B48","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'分开放雨直直直直恍恍恍翻'"},"transient":{},"execution_count":74}],"source":"model = RNNModel(rnn_layer, vocab_size).to(device)\npredict_rnn_pytorch('分开', 10, model, vocab_size, device, idx_to_char, char_to_idx)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_3bm44z0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"F3BA8B41B5E14E2191674147D2022A39","mdEditEnable":false},"source":"接下来实现训练函数，这里只使用了相邻采样。"},{"cell_type":"code","execution_count":75,"metadata":{"graffitiCellId":"id_kqdlzc9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"C6B0157AB1964E14AD52BFC3B4E8ACCE","collapsed":false,"scrolled":false},"outputs":[],"source":"def train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes):\n    loss = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    model.to(device)\n    for epoch in range(num_epochs):\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样\n        state = None\n        for X, Y in data_iter:\n            if state is not None:\n                # 使用detach函数从计算图分离隐藏状态\n                if isinstance (state, tuple): # LSTM, state:(h, c)  \n                    state[0].detach_()\n                    state[1].detach_()\n                else: \n                    state.detach_()\n            (output, state) = model(X, state) # output.shape: (num_steps * batch_size, vocab_size)\n            y = torch.flatten(Y.T)\n            l = loss(output, y.long())\n            # print(output.shape, y.long().shape)  # torch.Size([1120, 1027]) torch.Size([1120])\n            \n            optimizer.zero_grad()\n            l.backward()\n            grad_clipping(model.parameters(), clipping_theta, device)\n            optimizer.step()\n            l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n        \n\n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn_pytorch(\n                    prefix, pred_len, model, vocab_size, device, idx_to_char,\n                    char_to_idx))"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_0ejh2ag","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"E271EA2BA38045BF93AD1CD9484A3194","mdEditEnable":false},"source":"训练模型。"},{"metadata":{"id":"4A2FD18B701C4DFE8A33163A5F8D2E68","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"epoch 50, perplexity 13.224990, time 0.50 sec\n - 分开 我不了这样 我不的 我不我 你 我不多 我不我 你 我不多 我不我 你 我不多 我不我 你 我不多\n - 不分开 我不要你  我不要再想你 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 \nepoch 100, perplexity 1.333314, time 0.50 sec\n - 分开 我人的事生  后知道你在很美海家乡的让我感动的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的\n - 不分开 我来一个画  回的对不笑 让默默娘子 娘子却依旧每日 折一枝杨柳 你在那里 在小村外的溪边河口默默\nepoch 150, perplexity 1.070351, time 0.53 sec\n - 分开 我人怀事  有什么都会值得去  我想大声宣布 对你依依不舍 连隔壁邻居都猜到我现在的感受 河边的风\n - 不分开 我想一声宣  对你却依不会 语沉默 娘子却依旧每日折一枝杨柳 在小村外的溪边河口 默默的在等著我 \nepoch 200, perplexity 1.033641, time 0.50 sec\n - 分开 我人怀事 有一已去猜会年抱  你一起 融化在宇宙里 我每天每天每天在想想想想著你 这样的甜蜜 让我\n - 不分开 我不一定离 有轻什么不妥 有话就直说 别窝在角落 不爽就反驳 到底拽什么 懂不懂篮球 有种不要走 \nepoch 250, perplexity 1.021522, time 0.52 sec\n - 分开 我轻轻功叹息 后悔就这些什么 已经了是 是没有 烦要再 别打我妈妈 难道你手不会痛吗 其实我回家就\n - 不分开 我说一声三  步两步三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿 看远方的星\n","name":"stdout"}],"source":"num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\npred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\ntrain_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                            corpus_indices, idx_to_char, char_to_idx,\n                            num_epochs, num_steps, lr, clipping_theta,\n                            batch_size, pred_period, pred_len, prefixes)","execution_count":76},{"metadata":{"id":"82CBC18E48CC49A7A8C5B0BAB50D5B59","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"cell_type":"code","execution_count":20,"metadata":{"graffitiCellId":"id_kn2ynjc","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1FC86D37312346418E960DE255315FC0","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 50, perplexity 9.405654, time 0.52 sec\n - 分开始一起 三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿  一枝杨柳 你的那我 在\n - 不分开 爱情你的手 一人的老斑鸠 腿短毛不多 快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 快使用双截棍\nepoch 100, perplexity 1.255020, time 0.54 sec\n - 分开 我人了的屋我 一定令它心仪的母斑鸠 爱像一阵风 吹完美主  这样 还人的太快就是学怕眼口让我碰恨这\n - 不分开不想我多的脑袋有问题 随便说说 其实我早已经猜透看透不想多说 只是我怕眼泪撑不住 不懂 你的黑色幽默\nepoch 150, perplexity 1.064527, time 0.53 sec\n - 分开 我轻外的溪边 默默在一心抽离 有话不知不觉 一场悲剧 我对不起 藤蔓植物的爬满了伯爵的坟墓 古堡里\n - 不分开不想不多的脑 有教堂有你笑 我有多烦恼  没有你烦 有有样 别怪走 快后悔没说你 我不多难熬 我想就\nepoch 200, perplexity 1.033074, time 0.53 sec\n - 分开 我轻外的溪边 默默在一心向昏 的愿  古无着我只能 一个黑远 这想太久 这样我 不要再是你打我妈妈\n - 不分开你只会我一起睡著 样 娘子却只想你和汉堡 我想要你的微笑每天都能看到  我知道这里很美但家乡的你更美\nepoch 250, perplexity 1.047890, time 0.68 sec\n - 分开 我轻多的漫 却已在你人演  想要再直你 我想要这样牵着你的手不放开 爱可不可以简简单单没有伤害 你\n - 不分开不想不多的假  已无能为力再提起 决定中断熟悉 然后在这里 不限日期 然后将过去 慢慢温习 让我爱上\n","name":"stdout"}],"source":"num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\npred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\ntrain_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                            corpus_indices, idx_to_char, char_to_idx,\n                            num_epochs, num_steps, lr, clipping_theta,\n                            batch_size, pred_period, pred_len, prefixes)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}