{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_635azvh",
    "id": "B4BA5B0FCB884B6DBA6FFE071318505E",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 文本预处理\n",
    "\n",
    "\n",
    "文本是一类序列数据，一篇文章可以看作是字符或单词的序列，本节将介绍文本数据的常见预处理步骤，预处理通常包括四个步骤：\n",
    "\n",
    "1. 读入文本\n",
    "2. 分词\n",
    "3. 建立字典，将每个词映射到一个唯一的索引（index）\n",
    "4. 将文本从词的序列转换为索引的序列，方便输入模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_da72pg7",
    "id": "C3B3705CB33847A895AD10619F23E97B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 读入文本\n",
    "\n",
    "我们用一部英文小说，即H. G. Well的[Time Machine](http://www.gutenberg.org/ebooks/35)，作为示例，展示文本预处理的具体过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "graffitiCellId": "id_ytfpat1",
    "id": "7FA4C53DED4F42279EA3AB3229B88DB7",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentences 3221\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "def read_time_machine():\n",
    "    with open('./data/input/timemachine.txt', 'r') as f:\n",
    "        # 把所有非a-z的连续字符用空格替换\n",
    "        lines = [re.sub('[^a-z]+', ' ', line.strip().lower()) for line in f]\n",
    "    return lines\n",
    "\n",
    "\n",
    "lines = read_time_machine()\n",
    "print('# sentences %d' % len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "E6D28560E2E24538AC069A4CD0AF62DA",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'once have been the favoured aristocracy and the morlocks their'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_gy3tram",
    "id": "EABE813C62FC4E1B8DFFD7B819C31829",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 分词\n",
    "\n",
    "我们对每个句子进行分词，也就是将一个句子划分成若干个词（token），转换为一个词的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "graffitiCellId": "id_z5grfxp",
    "id": "F80F8AFC1C0A48BDB66D52A18DC3A940",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'time', 'machine', 'by', 'h', 'g', 'wells', ''], ['']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sentences, token='word'):\n",
    "    \"\"\"Split sentences into word or char tokens\"\"\"\n",
    "    if token == 'word':\n",
    "        return [sentence.split(' ') for sentence in sentences]\n",
    "    elif token == 'char':\n",
    "        return [list(sentence) for sentence in sentences]\n",
    "    else:\n",
    "        print('ERROR: unkown token type '+token)\n",
    "\n",
    "tokens = tokenize(lines)\n",
    "tokens[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_rap2ka4",
    "id": "01CE759264D84FAA8C60CE9156B86157",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 建立字典\n",
    "\n",
    "为了方便模型处理，我们需要将字符串转换为数字。因此我们需要先构建一个字典（vocabulary），将每个词映射到一个唯一的索引编号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BA532636BC98430886A7C4715EECB15D",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_corpus(sentences):  # 参数sentence 为二维数组\n",
    "    tokens = [tk for st in sentences for tk in st]  # 先转成一个list, 再统计词频\n",
    "    return collections.Counter(tokens)  # 返回一个字典，记录每个词的出现次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "graffitiCellId": "id_wapwqkb",
    "id": "37532FBF89C242A1805534BBE05C343A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
    "        counter = count_corpus(tokens)  # : 这里的tokens为词组成的二维数组。词组成的句子是list\n",
    "        self.token_freqs = list(counter.items())\n",
    "        self.idx_to_token = []\n",
    "        if use_special_tokens:\n",
    "            # padding, begin of sentence, end of sentence, unknown\n",
    "            self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
    "            self.idx_to_token += ['', '', '', '']\n",
    "        else:\n",
    "            self.unk = 0\n",
    "            self.idx_to_token += ['']\n",
    "        # token_freqs is list with tuple that each contains 2 element. such as [(‘nice’, 666), ...]\n",
    "        # 注意：这里的 token_freqs 不包含重复的元素\n",
    "        self.idx_to_token += [token for token, freq in self.token_freqs\n",
    "                        if freq >= min_freq and token not in self.idx_to_token]\n",
    "        self.token_to_idx = dict()\n",
    "        for idx, token in enumerate(self.idx_to_token):\n",
    "            self.token_to_idx[token] = idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        \"\"\"\n",
    "        token_to_index\n",
    "        把词转成索引号\n",
    "        \n",
    "        isinstance() 函数来判断一个对象是否是一个已知的类型，类似 type()。\n",
    "        \n",
    "        isinstance() 与 type() 区别：\n",
    "        \n",
    "            type() 不会认为子类是一种父类类型，不考虑继承关系。\n",
    "            isinstance() 会认为子类是一种父类类型，考虑继承关系。\n",
    "        \n",
    "        如果要判断两个类型是否相同推荐使用 isinstance()。\n",
    "        \"\"\"\n",
    "        if not isinstance(tokens, (list, tuple)):  # 只要是后面(list, tuple) 中的一个就返回True\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        \"\"\"\n",
    "        index_to_token\n",
    "        把索引号转成词\n",
    "        \"\"\"\n",
    "        if not isinstance(indices, (list, tuple)):  # 只要是后面(list, tuple) 中的一个就返回True\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=5>\n",
    "Python.__getitem__方法 -- 举个栗子🌰<br>\n",
    "</font>\n",
    "<br>\n",
    "\n",
    "<font color=red size=3>\n",
    "Python的魔法方法__getitem__ 可以让对象实现迭代功能，这样就可以使用for...in... 来迭代该对象了\n",
    "</font>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Animal' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-23ae33d7ccb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0manimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fish\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0manimal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manimals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Animal' object is not iterable"
     ]
    }
   ],
   "source": [
    "class Animal:\n",
    "    def __init__(self, animal_list):\n",
    "        self.animals_name = animal_list\n",
    "\n",
    "animals = Animal([\"dog\",\"cat\",\"fish\"])\n",
    "for animal in animals:\n",
    "    print(animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=3>\n",
    "在用 for..in.. 迭代对象时，如果对象没有实现 __iter__ __next__ 迭代器协议，Python的解释器就会去寻找__getitem__ 来迭代对象，如果连__getitem__ 都没有定义，这解释器就会报对象不是迭代器的错误： 如上所示\n",
    "</font>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "TypeError: 'Animal' object is not iterable\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=3>\n",
    "而实现这个方法后，就可以正常迭代对象了\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "cat\n",
      "fish\n"
     ]
    }
   ],
   "source": [
    "class Animal:\n",
    "    def __init__(self, animal_list):\n",
    "        self.animals_name = animal_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.animals_name[index]\n",
    "\n",
    "animals = Animal([\"dog\",\"cat\",\"fish\"])\n",
    "for animal in animals:\n",
    "    print(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat', 'fish']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.animals_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(animals.animals_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = ['a', 'b', 'c']\n",
    "arr.index('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_l6pjfl7",
    "id": "73D0F629056F41B59D4A53F15BFAB552",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 将词转为索引\n",
    "\n",
    "使用字典，我们可以将原文本中的句子从单词序列转换为索引序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "graffitiCellId": "id_k48bsl2",
    "id": "9FBB71C21B5C4F5283C70CFE3BB07112",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him', '']\n",
      "indices: [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0]\n",
      "words: ['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "indices: [20, 21, 22, 23, 24, 16, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, 10):\n",
    "    print('words:', tokens[i])  # token 为二维数组[['nice', 'to', 'meet', 'you'], ...]\n",
    "    print('indices:', vocab[tokens[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_k17qg7x",
    "id": "DB6949BC67FF4C7481DFFD00FE64BE56",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "我们看一个例子，这里我们尝试用Time Machine作为语料构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "23"
    },
    "graffitiCellId": "id_hm9y6bm",
    "id": "1BE94FF518DB4C4A8CDFB95C0262B47E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 0), ('the', 1), ('time', 2), ('machine', 3), ('by', 4), ('h', 5), ('g', 6), ('wells', 7), ('i', 8), ('traveller', 9)]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(tokens)\n",
    "print(list(vocab.token_to_idx.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4E3D318772A247FAB9E8B53542EE8C55",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "35832C2B98674D3A896B7FFD2B8CCC24",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'traveller']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.idx_to_token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "456ADC0B9BA940F6845A1AF1F028FCF9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95E3DB75E302405197823B142661FE7B",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 测试 `__getitem__()` 和 `to_tokens()` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "85EE2D315DA248629468B7DABBE5FE81",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self.unk 的index为0, 未登录词都被标记为 self.unk\n",
    "vocab.__getitem__(['mengfuli', 'the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'traveller'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "7122D6E490C24DE380B13CB659DEE717",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'the', 'time', 'machine', 'by', 'h', 'g', 'wells', 'i', 'traveller']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "vocab.to_tokens([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "02CBE71B394D48EA8D6CC2FB64AD7FA9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 9, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient']]  # word to index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_q6fupul",
    "id": "EA20BC8762A74B188D3FDD761BFEDE98",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 用现有工具进行分词\n",
    "\n",
    "我们前面介绍的分词方式非常简单，它至少有以下几个缺点:\n",
    "\n",
    "1. 标点符号通常可以提供语义信息，但是我们的方法直接将其丢弃了\n",
    "2. 类似“shouldn't\", \"doesn't\"这样的词会被错误地处理\n",
    "3. 类似\"Mr.\", \"Dr.\"这样的词会被错误地处理\n",
    "\n",
    "我们可以通过引入更复杂的规则来解决这些问题，但是事实上，有一些现有的工具可以很好地进行分词，我们在这里简单介绍其中的两个：[spaCy](https://spacy.io/)和[NLTK](https://www.nltk.org/)。\n",
    "\n",
    "下面是一个简单的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "graffitiCellId": "id_7u3knll",
    "id": "46F5F57611E248ECB51F04BD0104E278",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Mr. Chen doesn't agree with my suggestion.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ae3i5g2",
    "id": "7D5831E3D5AD4FF48155334F73065451",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "graffitiCellId": "id_uz6civu",
    "id": "30D69C6B1BE44362BA556E2E5EEF493A",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# doc = nlp(text)\n",
    "# print([token.text for token in doc])\n",
    "\n",
    "# 输出 ['Mr.', 'Chen', 'does', \"n't\", 'agree', 'with', 'my', 'suggestion', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "765CC9B5A1C348A58A2B340ADC532FD1",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "graffitiCellId": "id_r13iwga",
    "id": "B83D30D3670B44A38527B4943BE4DBE0",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk import data\n",
    "# data.path.append('./data/input/nltk_data')  # 数据600+M，这里没下载\n",
    "# print(word_tokenize(text))\n",
    "\n",
    "# ['Mr.', 'Chen', 'does', \"n't\", 'agree', 'with', 'my', 'suggestion', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19E1A2345BFD42CC849B7B864C5FF1C8",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
