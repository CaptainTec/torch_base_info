{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '酸菜鱼不错'],\n",
       " ['0', '轻食素食都是友善的饮食方式'],\n",
       " ['0', '完爆中午吃的农家乐'],\n",
       " ['1', '烤鱼很入味'],\n",
       " ['0', '有种入口即化的感觉'],\n",
       " ['0', '菜品一如既往的好'],\n",
       " ['0', '味道非常好'],\n",
       " ['0', '团购很优惠'],\n",
       " ['0', '咖喱牛腩不错'],\n",
       " ['0', '部分菜偏酸辣口']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        # print(len(lines))  # 16000\n",
    "        # print(type(lines))  # <class 'list'>\n",
    "        # print(lines[0])  # 0\t酸菜鱼不错\n",
    "        for line in lines:\n",
    "            mid_list = line.strip().split('\\t')\n",
    "            data.append(mid_list)\n",
    "    return data\n",
    "\n",
    "train_data = read_data('./data/Comments/train_shuffle.txt')\n",
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in vocab: 7817\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "def get_tokenized_comments(raw_data):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 数据的列表，列表中的每个元素为 [0/1标签, 文本字符串] 二元组\n",
    "    @return: 切分词后的文本的列表，列表中的每个元素为切分后的词序列 -> [[word1, word2, ...], 0/1标签]\n",
    "    '''\n",
    "    data = []\n",
    "    # data_label = []\n",
    "    for one in raw_data:\n",
    "        # data_label.append(one[0])\n",
    "        data.append(list(jieba.cut(one[1], cut_all=False, HMM=False)))\n",
    "    return data\n",
    "\n",
    "def get_vocab_comments(data):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 同上\n",
    "    @return: 数据集上的词典，Vocab 的实例（freqs, stoi, itos）\n",
    "    '''\n",
    "    mid_list = []\n",
    "    for st in get_tokenized_comments(data):\n",
    "        mid_list.extend(st)\n",
    "    counter = collections.Counter(mid_list)\n",
    "    return Vocab.Vocab(counter, min_freq=1)\n",
    "\n",
    "vocab = get_vocab_comments(train_data)\n",
    "print('# words in vocab:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = get_tokenized_comments(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(one) for one in mid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi['酸菜鱼']  # words to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'酸菜鱼'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'的'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.itos[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词典和词语的索引创建好后，就可以将数据集的文本从字符串的形式转换为单词下标序列的形式，以待之后的使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_comments(data, vocab):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 同上，原始的读入数据\n",
    "        vocab: 训练集上生成的词典\n",
    "    @return:\n",
    "        features: 单词下标序列，形状为 (n, max_l) 的整数张量\n",
    "        labels: 情感标签，形状为 (n,) 的0/1整数张量\n",
    "    '''\n",
    "    max_len = 15  # 将每条评论通过截断或者补0，使得长度变成15\n",
    "\n",
    "    def pad(x):\n",
    "        return x[:max_len] if len(x) > max_len else x + [0] * (max_len - len(x))\n",
    "\n",
    "    tokenized_data = get_tokenized_comments(data)  # [['酸菜鱼', '不错'], ...]\n",
    "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels = torch.tensor([int(one[0]) for one in data])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = preprocess_comments(train_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16000, 15])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 288,    4,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [ 742,  272, 1544,    9,   10, 4685,    2, 7677, 2010,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [ 157,  505, 1124,   15,    2, 1912,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [ 482,    3,   71,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [ 200,  254,  354,  332,    2,   26,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [  49,   12,    2,    6,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [   7,   14,    6,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [  67,    3, 1028,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [  97,  298,    4,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0],\n",
       "        [1382,   36,  155,  744,  458,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据迭代器\n",
    "\n",
    "利用 [`torch.utils.data.TensorDataset`](https://pytorch.org/docs/stable/data.html?highlight=tensor%20dataset#torch.utils.data.TensorDataset)，可以创建 PyTorch 格式的数据集，从而创建数据迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 15]) y torch.Size([64])\n",
      "#batches: 250\n"
     ]
    }
   ],
   "source": [
    "train_set = Data.TensorDataset(*preprocess_comments(train_data, vocab))\n",
    "# test_set = Data.TensorDataset(*preprocess_comments(test_data, vocab))  # 测试集标签未知\n",
    "\n",
    "# 上面的代码等价于下面的注释代码\n",
    "# train_features, train_labels = preprocess_imdb(train_data, vocab)\n",
    "# test_features, test_labels = preprocess_imdb(test_data, vocab)\n",
    "# train_set = Data.TensorDataset(train_features, train_labels)\n",
    "# test_set = Data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# len(train_set) = features.shape[0] or labels.shape[0]\n",
    "# train_set[index] = (features[index], labels[index])\n",
    "\n",
    "batch_size = 64\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "# test_iter = Data.DataLoader(test_set, batch_size)  # 测试集标签未知\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    break\n",
    "print('#batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
